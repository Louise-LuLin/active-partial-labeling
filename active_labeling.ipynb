{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Cuda: True ===\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.autograd import Variable  \n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from tqdm import tqdm\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy.special import softmax\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import CountVectorizer as CV\n",
    "import re\n",
    "import copy\n",
    "from itertools import combinations \n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from sklearn_crfsuite import CRF\n",
    "import nltk\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "print (\"== Cuda: {} ===\".format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence Loader\n",
    "class BuildDataLoader:\n",
    "    \n",
    "    def __init__(self, source, folder, num_flag, embed_flag):\n",
    "        self.sequence = []\n",
    "        self.word_dict = {}\n",
    "        self.label_dict = {}\n",
    "        self.num_flag = num_flag\n",
    "        self.embed_flag = embed_flag\n",
    "        self.folder = folder\n",
    "\n",
    "        if source == 'conll':\n",
    "            with open(folder + \"train.txt\", 'r') as file:\n",
    "                x=[]\n",
    "                y=[]\n",
    "                for line in file:\n",
    "                    tokens = line.replace(\"\\n\",'').split()\n",
    "                    if len(tokens) < 1:\n",
    "                        self.sequence.append((x,y))\n",
    "                        x = []\n",
    "                        y = []\n",
    "                    else:\n",
    "                        char = tokens[0]\n",
    "                        label = tokens[2]\n",
    "                        if self.num_flag and char.replace('.','').isdigit():\n",
    "                            char = 'NUM'\n",
    "                        x.append(char)\n",
    "                        y.append(label)\n",
    "                        if char not in self.word_dict:\n",
    "                            self.word_dict[char] = len(self.word_dict)\n",
    "                        if label not in self.label_dict:\n",
    "                            self.label_dict[label] = len(self.label_dict)\n",
    "        else:\n",
    "            with open(folder + '_string.txt', 'r') as x_file, open(folder + '_label.txt', 'r') as y_file: \n",
    "                for x, y in zip(x_file, y_file):\n",
    "                    x = [char for char in x.replace(\"\\n\",'')]\n",
    "                    y = y.replace(\"\\n\",'').split(',')\n",
    "                    if(len(y) > 1):\n",
    "                        if len(y[-1]) == 0:\n",
    "                            y = y[:-1]\n",
    "                        if self.num_flag:\n",
    "                            for i in range(len(x)):\n",
    "                                if x[i].isdigit():\n",
    "                                    x[i] = 'x'\n",
    "                        for char, label in zip(x, y):\n",
    "                            if char not in self.word_dict:\n",
    "                                self.word_dict[char] = len(self.word_dict)\n",
    "                            if label not in self.label_dict:\n",
    "                                self.label_dict[label] = len(self.label_dict)\n",
    "                        self.sequence.append((x, y))\n",
    "    \n",
    "    def shuffle(self, seed = 4):\n",
    "        random.Random(4).shuffle(self.sequence)\n",
    "    \n",
    "    def seqs2Tensor(self, sequence):\n",
    "        if self.embed_flag:\n",
    "            num_str = \"NUM\" if self.num_flag else \"\"\n",
    "            wv = KeyedVectors.load(self.folder + \"word2vec\" + num_str + \".kv\", mmap='r')\n",
    "            char_embed = []\n",
    "            for j, char in enumerate(sequence[0]):\n",
    "                    char_embed.append(wv[char])\n",
    "            tensor = torch.from_numpy(np.array(char_embed)).type(torch.FloatTensor)\n",
    "            return tensor.unsqueeze(0).to(device)\n",
    "        else:\n",
    "            tensor = torch.zeros(len(sequence[0]), len(self.word_dict), device=device)\n",
    "            for j, char in enumerate(sequence[0]):\n",
    "                    tensor[j][self.word_dict[char]] = 1\n",
    "            return tensor.unsqueeze(0).to(device)\n",
    "    \n",
    "    def get_embed_size(self):\n",
    "        if self.embed_flag:\n",
    "            num_str = \"NUM\" if self.num_flag else \"\"\n",
    "            wv = KeyedVectors.load(self.folder + \"word2vec\" + num_str + \".kv\", mmap='r')\n",
    "            return wv.vector_size\n",
    "        else:\n",
    "            return len(self.word_dict)\n",
    "    \n",
    "    def get_word_dict(self):\n",
    "        return self.word_dict\n",
    "    \n",
    "    def get_label_dict(self):\n",
    "        return self.label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRF\n",
    "class CrfModel(object):\n",
    "    \n",
    "    def __init__(self, data, feature):\n",
    "        self.label_dict = data.label_dict\n",
    "        self.word_dict = data.word_dict\n",
    "        self.num_flag = data.num_flag\n",
    "        self.feature = feature\n",
    "        \n",
    "        self.crf = CRF(\n",
    "            algorithm='lbfgs',\n",
    "            c1=0.1,\n",
    "            c2=0.1,\n",
    "            max_iterations=100,\n",
    "            all_possible_transitions=True\n",
    "        )\n",
    "        \n",
    "        self.X_train=[]\n",
    "        self.Y_train=[]\n",
    "    \n",
    "        print ('label dict size: {}'.format(len(self.label_dict)))\n",
    "        print ('word dict size: {}'.format(len(self.word_dict)))\n",
    "    def reset(self):\n",
    "        self.X_train=[]\n",
    "        self.Y_train=[]\n",
    "    \n",
    "    def char2feature(self, sent, i):\n",
    "        # obtain some overall information of the point name string\n",
    "        num_part = 4\n",
    "        len_string = len(sent)\n",
    "        mod = len_string % num_part\n",
    "        part_size = int(math.floor(len_string/num_part))\n",
    "        # determine which part the current character belongs to\n",
    "        # larger part will be at the beginning if the whole sequence can't be divided evenly\n",
    "        size_list = []\n",
    "        mod_count = 0\n",
    "        for j in range(num_part):\n",
    "            if mod_count < mod:\n",
    "                size_list.append(part_size+1)\n",
    "                mod_count += 1\n",
    "            else:\n",
    "                size_list.append(part_size)\n",
    "        # for current character\n",
    "        part_cumulative = [0]*num_part\n",
    "        for j in range(num_part):\n",
    "            if j > 0:\n",
    "                part_cumulative[j] = part_cumulative[j-1] + size_list[j]\n",
    "            else:\n",
    "                part_cumulative[j] = size_list[j] - 1   # indices start from 0\n",
    "        part_indicator = [0]*num_part\n",
    "        for j in range(num_part):\n",
    "            if part_cumulative[j] >= i:\n",
    "                part_indicator[j] = 1\n",
    "                break\n",
    "        word = sent[i]\n",
    "        if self.num_flag and word.isdigit():\n",
    "            itself = 'x'\n",
    "        else:\n",
    "            itself = word\n",
    "        features = {'0:word': itself}\n",
    "        # for previous character\n",
    "        if i > 0:\n",
    "            part_indicator = [0] * num_part\n",
    "            for j in range(num_part):\n",
    "                if part_cumulative[j] >= i-1:\n",
    "                    part_indicator[j] = 1\n",
    "                    break\n",
    "            word1 = sent[i-1]\n",
    "            if self.num_flag and word1.isdigit():\n",
    "                itself1 = 'x'\n",
    "            else:\n",
    "                itself1 = word1\n",
    "            itself1 = word1\n",
    "            features.update({'-1:word': itself1})\n",
    "        # for next character\n",
    "        if i < len(sent)-1:\n",
    "            part_indicator = [0] * num_part\n",
    "            for j in range(num_part):\n",
    "                if part_cumulative[j] >= i + 1:\n",
    "                    part_indicator[j] = 1\n",
    "                    break\n",
    "            word1 = sent[i+1]\n",
    "            if self.num_flag and word1.isdigit():\n",
    "                itself1 = 'x'\n",
    "            else:\n",
    "                itself1 = word1\n",
    "            itself1 = word1\n",
    "            features.update({'+1:word': itself1})\n",
    "        return features\n",
    "    \n",
    "    def add_instances(self, sequences):\n",
    "        for seq in sequences:\n",
    "            x = seq[0]\n",
    "            y = seq[1]\n",
    "            self.X_train.append([self.char2feature(x, i) for i in range(len(x))])\n",
    "            self.Y_train.append(y)\n",
    "    \n",
    "    def compute_confidence(self, sequence):\n",
    "        x = [self.char2feature(sequence[0], i) for i in range(len(sequence[0]))]\n",
    "        y_pred = self.crf.tagger_.tag(x)\n",
    "        prob_norm = math.exp(math.log(self.crf.tagger_.probability(y_pred)) / len(x))\n",
    "        \n",
    "        label_list = self.crf.tagger_.labels()\n",
    "        prob_list = []\n",
    "        for i in range(len(x)):\n",
    "            marginal_prob = [self.crf.tagger_.marginal(k, i) for k in label_list]\n",
    "            prob_list.append(max(marginal_prob))\n",
    "        return (prob_list, sum(prob_list), prob_norm)\n",
    "    \n",
    "    def compute_entropy(self, sequence):\n",
    "        x = [self.char2feature(sequence[0], i) for i in range(len(sequence[0]))]\n",
    "        label_list = self.crf.tagger_.labels()\n",
    "        self.crf.tagger_.set(x)\n",
    "        entropy_seq = []\n",
    "        for i in range(len(x)):\n",
    "            marginal_prob = [self.crf.tagger_.marginal(k, i) for k in label_list]\n",
    "            entropy_seq.append(scipy.stats.entropy(marginal_prob))\n",
    "        return (entropy_seq, sum(entropy_seq))\n",
    "    \n",
    "    def train(self):\n",
    "        self.crf.fit(self.X_train, self.Y_train) \n",
    "        return len(self.X_train)\n",
    "    \n",
    "    def predict(self, sequence):\n",
    "        x = [self.char2feature(sequence[0], i) for i in range(len(sequence[0]))]\n",
    "        return self.crf.tagger_.tag(x)    \n",
    "    \n",
    "    def evaluate_acc(self, sequences):\n",
    "        # Calculate phrase-level accuracy and out-of-phrase accuracy\n",
    "        X_test = [[self.char2feature(seq[0], i) for i in range(len(seq[0]))] for seq in sequences]\n",
    "        Y_test = [seq[1] for seq in sequences]\n",
    "        Y_pred = self.crf.predict(X_test)\n",
    "        \n",
    "        # Consider the accuracy in phrase level.\n",
    "        in_cnt,  in_crt = 0, 0    # Total/correct number of phrases\n",
    "        out_cnt, out_crt = 0, 0   # Total/correct number of \"o\"\n",
    "        all_cnt, all_crt = 0, 0   # Total/correct number of all words\n",
    "\n",
    "        acc = []\n",
    "        for y_test, y_pred in zip(Y_test, Y_pred):\n",
    "            cnt, crt = 0, 0\n",
    "            correct_flag = False\n",
    "            for j in range(len(y_test)):\n",
    "                all_cnt += 1\n",
    "                cnt += 1\n",
    "                if y_test[j] == y_pred[j]:\n",
    "                    all_crt += 1\n",
    "                    crt += 1\n",
    "\n",
    "                # If the character is a beginning-of-phrase.\n",
    "                if y_test[j][0] == 'b':\n",
    "                    in_cnt += 1\n",
    "                    if y_test[j] == y_pred[j]:\n",
    "                        if correct_flag:\n",
    "                            in_crt += 1\n",
    "                        correct_flag = True\n",
    "                    else:\n",
    "                        if correct_flag:\n",
    "                            if y_pred[j][2:] != y_pred[j-1][2:]:  # special case\n",
    "                                in_crt += 1\n",
    "                        correct_flag = False\n",
    "\n",
    "                # If the character is an inside-of-phrase.\n",
    "                elif y_test[j][0] == 'i':\n",
    "                    if y_test[j] != y_pred[j]:\n",
    "                        correct_flag = False\n",
    "\n",
    "                # If the character is an out-of-phrase.\n",
    "                elif y_test[j][0] == 'o':\n",
    "                    out_cnt += 1\n",
    "                    if y_test[j] == y_pred[j]:\n",
    "                        out_crt += 1\n",
    "                        if correct_flag:\n",
    "                            in_crt += 1\n",
    "                            correct_flag = False\n",
    "                    else:\n",
    "                        if correct_flag:\n",
    "                            if y_pred[j][2:] != y_pred[j-1][2:]:  # special case\n",
    "                                in_crt += 1\n",
    "                            correct_flag = False\n",
    "\n",
    "            acc.append(crt/cnt)\n",
    "            # For the case where the phrase is at the end of a string.\n",
    "            if correct_flag:\n",
    "                in_crt += 1\n",
    "        in_acc = 0 if in_cnt == 0 else in_crt/in_cnt\n",
    "        out_acc = 0 if out_cnt == 0 else out_crt/out_cnt\n",
    "        all_acc = 0 if all_cnt == 0 else all_crt/all_cnt \n",
    "            \n",
    "        return in_acc, out_acc, all_acc, sum(acc)/len(acc)\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        loc = {'0':0, '-1':1, '+1':2}\n",
    "        if self.feature == 'all':\n",
    "            paras = torch.zeros(len(loc) * len(self.word_dict) + len(self.label_dict), len(self.label_dict), device=device)\n",
    "            for (attr, label), weight in self.crf.state_features_.items():\n",
    "                attr = attr.split(\":\")\n",
    "                dim1 = loc[attr[0]] * self.word_dict[':'.join(attr[2:])]\n",
    "                dim2 = self.label_dict[label]\n",
    "                paras[dim1][dim2] = weight\n",
    "            for (label_from, label_to), weight in self.crf.transition_features_.items():\n",
    "                dim1 = len(loc) * len(self.word_dict) + self.label_dict[label_from]\n",
    "                dim2 = self.label_dict[label_to]\n",
    "                paras[dim1][dim2] = weight\n",
    "        elif self.feature == 'node':\n",
    "            paras = torch.zeros(len(loc) * len(self.word_dict), len(self.label_dict), device=device)\n",
    "            for (attr, label), weight in self.crf.state_features_.items():\n",
    "                attr = attr.split(\":\")\n",
    "                dim1 = loc[attr[0]] * self.word_dict[':'.join(attr[2:])]\n",
    "                dim2 = self.label_dict[label]\n",
    "                paras[dim1][dim2] = weight\n",
    "        else:\n",
    "            paras = torch.zeros(len(self.label_dict), len(self.label_dict), device=device)\n",
    "            for (label_from, label_to), weight in self.crf.transition_features_.items():\n",
    "                dim1 = self.label_dict[label_from]\n",
    "                dim2 = self.label_dict[label_to]\n",
    "                paras[dim1][dim2] = weight\n",
    "                \n",
    "        paras = paras.unsqueeze(0).unsqueeze(0).to(device) # batch, channel, w, h\n",
    "        return paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize a set of string by n-grams.\n",
    "def string_vectorize(Xs_list):\n",
    "    vc = CV(analyzer='char_wb', ngram_range=(3, 4), min_df=1, token_pattern='[a-z]{2,}')\n",
    "    name = []\n",
    "    for i in Xs_list:\n",
    "        s = re.findall('(?i)[a-z]{2,}', \"\".join(str(x) for x in i))\n",
    "        name.append(' '.join(s))\n",
    "    vc.fit(name)\n",
    "    vec = vc.transform(name).toarray()\n",
    "    # print(name)\n",
    "    # print(vec)\n",
    "    dictionary = vc.get_feature_names()\n",
    "    return vec, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replay buffer: a cyclic buffer of bounded size that holds the transitions observed recently\n",
    "Transition = namedtuple('Transition',\n",
    "                       ('state', 'action', 'next_state', 'reward', 'sequences'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "    \n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-network\n",
    "class DQN(nn.Module):\n",
    "    \n",
    "    def __init__(self, para_h, para_w, w_dim, rnn_hidden, n_filters, filter_size, n_stride):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        # CNN for CRF parameters\n",
    "        self.conv1 = nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=n_filters,   \n",
    "                kernel_size=filter_size,              \n",
    "                stride=n_stride,        \n",
    "            )\n",
    "        self.bn1 = nn.BatchNorm2d(n_filters)\n",
    "        self.conv2 = nn.Conv2d(n_filters, n_filters*2, filter_size, n_stride)\n",
    "        self.bn2 = nn.BatchNorm2d(n_filters*2)\n",
    "        self.conv3 = nn.Conv2d(n_filters*2, n_filters*2, filter_size, n_stride)\n",
    "        self.bn3 = nn.BatchNorm2d(n_filters*2)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = filter_size, stride = n_stride):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(para_w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(para_h)))\n",
    "        linear_input_size = convw * convh * n_filters * 2\n",
    "        \n",
    "        self.fc1 = nn.Linear(linear_input_size, rnn_hidden)\n",
    "        \n",
    "        # LSTM for w sequence\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=w_dim,\n",
    "            hidden_size=rnn_hidden, \n",
    "            num_layers=1,\n",
    "            batch_first=True,  # input＆output (batch，time_step，input_size)\n",
    "        )\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(2 * rnn_hidden, 1)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, crf_x, seq_x):\n",
    "        # CNN\n",
    "        x1 = F.relu(self.bn1(self.conv1(crf_x)))\n",
    "        x1 = F.relu(self.bn2(self.conv2(x1)))\n",
    "        x1 = F.relu(self.bn3(self.conv3(x1)))\n",
    "        x1 = F.relu(self.fc1(x1.view(x1.size(0), -1)))\n",
    "        \n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size) \n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        r_out,_ = self.rnn(seq_x, None) \n",
    "        # output of last time step\n",
    "#         rnn_out = self.out(r_out[:, -1, :])\n",
    "        x2 = r_out[:, -1, :]\n",
    "        x = torch.cat((x1, x2), 1)\n",
    "        \n",
    "        return self.fc(x) # flatten the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state, sequences, greedy_select):\n",
    "    max_idx = 0\n",
    "    \n",
    "    if greedy_select == 'te':\n",
    "        prob_list = []\n",
    "        for seq in sequences:\n",
    "            (prob_per_token, prob_sum) = crf.compute_entropy(seq)\n",
    "            prob_list.append(prob_sum/len(seq[1]))\n",
    "        # normalize\n",
    "        mean_prob = np.mean(prob_list)\n",
    "        std_prob = np.std(prob_list)\n",
    "        prob_list = [(prob_list[i] - mean_prob) / std_prob for i in range(len(sequences))]\n",
    "        max_idx = np.argsort(np.array(prob_list), kind='mergesort').tolist()[::-1][0]\n",
    "    \n",
    "    max_q_value = policy_net(state, data.seqs2Tensor(sequences[max_idx]))\n",
    "\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = 0.3\n",
    "#     eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "#         math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    \n",
    "    if sample < eps_threshold:\n",
    "        return (0, max_idx, max_q_value)\n",
    "    \n",
    "    for i in range(len(sequences)):\n",
    "        seq = sequences[i]\n",
    "#         q_value = policy_net(get_state_action(seq, state))\n",
    "        q_value = policy_net(state, data.seqs2Tensor(seq))\n",
    "        if max_q_value < q_value:\n",
    "            max_q_value = q_value\n",
    "            max_idx = i\n",
    "    return (1, max_idx, max_q_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reward(crf, validation_list, test_list, sim_weight, trans_flag):\n",
    "    if trans_flag == 'test2T':\n",
    "        source_seqs = test_list\n",
    "        target_seqs = test_list\n",
    "    elif trans_flag == 'test2V':\n",
    "        source_seqs = test_list\n",
    "        target_seqs = validation_list\n",
    "    elif trans_flag == 'valid2V':\n",
    "        source_seqs = validation_list\n",
    "        target_seqs = validation_list\n",
    "    else:\n",
    "        source_seqs = validation_list\n",
    "        target_seqs = test_list\n",
    "\n",
    "    source_q = gen_dataDistr(source_seqs)\n",
    "    target_q = gen_dataDistr(target_seqs)\n",
    "    acc_reweight = []\n",
    "    idx = []\n",
    "    for i, seq in enumerate(source_seqs):\n",
    "        _, _, _, acc = crf.evaluate_acc([seq])\n",
    "        x = \",\".join(str(char) for char in seq[1])\n",
    "        if trans_flag == 'kmers':\n",
    "            acc_reweight.append(sim_weight[i] * acc)\n",
    "            idx.append(i)\n",
    "        elif x in target_q:\n",
    "            acc_reweight.append((target_q[x] / len(target_seqs)) / (source_q[x] / len(source_seqs)) * acc)\n",
    "            idx.append(i)\n",
    "    minidx = np.argsort(acc_reweight)\n",
    "    errseq = [source_seqs[idx[i]] for i in minidx[:10]]\n",
    "    pred = [crf.predict(err) for err in errseq]\n",
    "    if trans_flag == 'kmers':\n",
    "        acc = sum(acc_reweight)\n",
    "    else:\n",
    "        acc = sum(acc_reweight)/len(source_seqs)\n",
    "    return (acc, errseq, pred)\n",
    " \n",
    "    # confidence on test set\n",
    "#     conf = 0\n",
    "#     for seq in test_list:\n",
    "#         conf += crf.compute_entropy(seq)[-1]/len(seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    \n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.uint8)\n",
    "    \n",
    "#     state_batch = []\n",
    "#     for i in range(len(batch.state)):\n",
    "#         state_actions.append(get_state_action(batch.action[i], batch.state[i]))\n",
    "    \n",
    "    state_batch  = torch.cat(batch.state)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "    # padding sequences\n",
    "    seq_lengths = []\n",
    "    embed_dim = 0\n",
    "    batch_size = 0\n",
    "    for a in batch.action:\n",
    "        seq_lengths.append(a.shape[1])\n",
    "        embed_dim = a.shape[2]\n",
    "        batch_size += 1\n",
    "    max_len = max(seq_lengths)\n",
    "    action_batch = torch.zeros((batch_size, max_len, embed_dim), device=device)\n",
    "    for i, a in enumerate(batch.action):\n",
    "        a = a.squeeze(0)\n",
    "        if a.shape[0] < max_len:\n",
    "            padding = torch.zeros((max_len - a.shape[0], embed_dim), device=device)\n",
    "            a = torch.cat([a, padding])\n",
    "        action_batch[i] = a\n",
    "#     action_batch = torch.nn.utils.rnn.pack_padded_sequence(actions, seq_lengths, batch_first=True, enforce_sorted=False)  \n",
    "\n",
    "    next_states = [s for s in batch.next_state if s is not None]\n",
    "    next_state_actions = []\n",
    "    next_reward = []\n",
    "    for i in range(len(next_states)):\n",
    "        next_s = next_states[i]\n",
    "        max_q_value = -sys.maxsize - 1\n",
    "        max_idx = 0\n",
    "        for seq in batch.sequences[i]:\n",
    "#             q_value = target_net(get_state_action(seq, next_s))\n",
    "            q_value = target_net(next_s, data.seqs2Tensor(seq))\n",
    "            if max_q_value < q_value:\n",
    "                max_q_value = q_value\n",
    "                max_idx = i\n",
    "        next_reward.append(max_q_value)\n",
    "    \n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = torch.cat(next_reward).squeeze(1)\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    policy_net.train()\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== data setup ===\n",
      "pretrain  : 45\n",
      "candidate : 600\n",
      "validation: 200\n",
      "test      : 200\n"
     ]
    }
   ],
   "source": [
    "# Train Q-function\n",
    "BATCH_SIZE = 5\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 20\n",
    "TARGET_UPDATE = 20\n",
    "\n",
    "SOURCE = 'conll'\n",
    "METHOD = 'RL'\n",
    "if SOURCE == 'conll':\n",
    "    DATA_PATH = \"./datasets/conll2000/\" + SOURCE\n",
    "else:\n",
    "    DATA_PATH = \"./datasets/building/\" + SOURCE\n",
    "CRF_PRETRAIN_SIZE = 5\n",
    "AGENT_PRETRAIN_SIZE = 45\n",
    "CANDIDATE_SIZE = 600\n",
    "VALIDATE_SIZE = 200\n",
    "TEST_SIZE = 200\n",
    "BUDGET = 115\n",
    "FEAT = 'all' # all or node or edge\n",
    "GREEDY = 'te' # rand or te\n",
    "FIX_FLAG = False\n",
    "NUM_FLAG = True\n",
    "EMBED_FLAG = True\n",
    "TRANS = 'kmers' # kmers or valid2V or valid2T or test2V or test2T\n",
    "LOOP_SIZE = 5\n",
    "LOOP_CANDI = 3\n",
    "INITIAL_FLAG = True\n",
    "REWARD = 'acc' # acc, conf, diff, all\n",
    "RNN_HIDDEN = 64\n",
    "N_FILTER = 16\n",
    "FILTER_SIZE = 4\n",
    "N_STRIDE = 2\n",
    "LR = 0.001\n",
    "\n",
    "# Load data\n",
    "data = BuildDataLoader(SOURCE, DATA_PATH, NUM_FLAG, EMBED_FLAG)\n",
    "data.shuffle(8)\n",
    "pretrain_crf_list = data.sequence[:CRF_PRETRAIN_SIZE]\n",
    "pretrain_agt_list = data.sequence[:AGENT_PRETRAIN_SIZE]\n",
    "test_list = data.sequence[-TEST_SIZE:]\n",
    "validation_list = data.sequence[-TEST_SIZE - VALIDATE_SIZE : -TEST_SIZE]\n",
    "candidate_list  = data.sequence[AGENT_PRETRAIN_SIZE : AGENT_PRETRAIN_SIZE + CANDIDATE_SIZE]\n",
    "print (\"=== data setup ===\")\n",
    "print (\"pretrain  : {}\".format(len(pretrain_agt_list)))\n",
    "print (\"candidate : {}\".format(len(candidate_list)))\n",
    "print (\"validation: {}\".format(len(validation_list)))\n",
    "print (\"test      : {}\".format(len(test_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_weight = np.zeros((len(candidate_list), len(test_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate size: 600\n",
      "validate size: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [06:10<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Vectorized and clustered test set.\n",
    "Xs = [seq[0] for seq in test_list]\n",
    "Xs.extend([seq[0] for seq in candidate_list])\n",
    "vec, _ = string_vectorize(Xs)\n",
    "test_vec = vec[:len(test_list)].tolist()\n",
    "candidate_vec = vec[len(test_list):].tolist()\n",
    "print (\"candidate size: \" + str(len(candidate_vec)))\n",
    "print (\"validate size: \" + str(len(test_vec)))\n",
    "\n",
    "# Pre-calculate similarity: both between validation-test and validation-validate\n",
    "sim_matrix_test = np.zeros((len(candidate_vec), len(test_vec)))\n",
    "try:\n",
    "    with tqdm(range(len(candidate_vec))) as iterator:\n",
    "        for i in iterator:\n",
    "            for j in range(len(test_vec)):\n",
    "                # cosine distance is 1-cosine(a,b)\n",
    "                sim_matrix_test[i, j] = 1 - scipy.spatial.distance.cosine(candidate_vec[i], test_vec[j])\n",
    "except KeyboardInterrupt:\n",
    "    iterator.close()\n",
    "    raise\n",
    "iterator.close()\n",
    "sim_weight = softmax(np.sum(sim_matrix_test, axis=1) / sim_matrix_test.shape[1])\n",
    "print ('Similarity done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set has 198 formats\n",
      "validation set has 200 formats\n",
      "candidate set has 590 formats\n",
      "valid & test / test: 0.010101010101010102\n"
     ]
    }
   ],
   "source": [
    "# generate data distribution\n",
    "def gen_dataDistr(sequences):\n",
    "    data_q = {}\n",
    "    for seq in sequences:\n",
    "        x = \",\".join(str(char) for char in seq[1])\n",
    "        if x not in data_q:\n",
    "            data_q[x] = 1\n",
    "        else:\n",
    "            data_q[x] += 1\n",
    "    return data_q\n",
    "\n",
    "def add_dataformat(data_dict, sequences):\n",
    "    for seq in sequences:\n",
    "        x = \"\".join(str(char) for char in seq[0])\n",
    "        if x not in data_dict:\n",
    "            data_dict[x] = len(data_dict)\n",
    "    return data_dict\n",
    "        \n",
    "# Check the overlapping of data format\n",
    "test_q = gen_dataDistr(test_list)\n",
    "print (\"test set has {} formats\".format(len(test_q)))\n",
    "\n",
    "valid_q = gen_dataDistr(validation_list)\n",
    "print (\"validation set has {} formats\".format(len(valid_q)))\n",
    "\n",
    "candidate_q = gen_dataDistr(candidate_list)\n",
    "print (\"candidate set has {} formats\".format(len(candidate_q)))\n",
    "\n",
    "valid_test_ratio = len(set.intersection(set(test_q.keys()),set(valid_q.keys()))) / len(test_q)\n",
    "print (\"valid & test / test: {}\".format(valid_test_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label dict size: 22\n",
      "word dict size: 17671\n",
      "CNN (row, column)=(53035, 22)\n",
      "RNN input=100\n",
      "DQN parameter size: 13639857\n"
     ]
    }
   ],
   "source": [
    "# Pretrain CRF\n",
    "crf = CrfModel(data, FEAT)\n",
    "crf.add_instances(pretrain_crf_list)\n",
    "crf.train()\n",
    "\n",
    "_, _, para_h, para_w = crf.get_parameters().size()\n",
    "input_size = data.get_embed_size()\n",
    "print (\"CNN (row, column)=({}, {})\".format(para_h, para_w))\n",
    "print (\"RNN input={}\".format(input_size))\n",
    "\n",
    "# Initialize DQN\n",
    "policy_net = DQN(para_h, para_w, input_size, RNN_HIDDEN, N_FILTER, FILTER_SIZE, N_STRIDE).to(device)\n",
    "# target_net = DQN(para_h, para_w, input_size, RNN_HIDDEN, N_FILTER, FILTER_SIZE, N_STRIDE).to(device)\n",
    "target_net = copy.deepcopy(policy_net)\n",
    "para_size = sum(p.numel() for p in policy_net.parameters() if p.requires_grad)\n",
    "print ('DQN parameter size: {}'.format(para_size))\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LR)\n",
    "\n",
    "memory = ReplayMemory(50)\n",
    "\n",
    "steps_done = 0\n",
    "random.seed(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Pretrain the agent\n",
    "try:\n",
    "    with tqdm(range(50)) as iterator:\n",
    "        for i_episode in iterator:\n",
    "            # Initialize the environment and state\n",
    "            pretrain_agt_list = data.sequence[:AGENT_PRETRAIN_SIZE]\n",
    "            crf.reset()\n",
    "            pretrain_idx = random.sample(range(len(pretrain_agt_list)), CRF_PRETRAIN_SIZE)\n",
    "            crf.add_instances([pretrain_agt_list[i] for i in pretrain_idx])\n",
    "            crf.train()\n",
    "\n",
    "            old_reward, _, _ = calculate_reward(crf, validation_list, test_list, sim_weight, TRANS)\n",
    "            state = crf.get_parameters()\n",
    "\n",
    "            # Reduce actions\n",
    "            pretrain_agt_list = [pretrain_agt_list[i] for i in range(len(pretrain_agt_list)) if i not in pretrain_idx]\n",
    "\n",
    "            while len(pretrain_agt_list) > 1:\n",
    "                # Select and perform an action\n",
    "                _, query_idx, _ = select_action(state, pretrain_agt_list, GREEDY)\n",
    "                query_instance = pretrain_agt_list.pop(query_idx)\n",
    "                action = data.seqs2Tensor(query_instance)\n",
    "\n",
    "                # Env (CRF) give reward\n",
    "                crf.add_instances([query_instance])\n",
    "                crf.train()\n",
    "\n",
    "                cur_reward, _, _ = calculate_reward(crf, validation_list, test_list, sim_weight, TRANS)\n",
    "                reward = cur_reward - old_reward\n",
    "                old_reward = cur_reward\n",
    "                reward = torch.tensor([reward], device=device)\n",
    "\n",
    "                # Observe new state\n",
    "                next_state = crf.get_parameters()\n",
    "\n",
    "                # Store the transition in memory\n",
    "                if len(pretrain_agt_list) == 0: print (\"Warning!\")\n",
    "                memory.push(state, action, next_state, reward, [seq for seq in pretrain_agt_list])\n",
    "\n",
    "                # Move to the next state\n",
    "                state = next_state\n",
    "\n",
    "                # Perform one step of the optimization (on the target network)\n",
    "                optimize_model()\n",
    "            # Update the target network, copying all weights and biases in DQN\n",
    "            if i_episode % TARGET_UPDATE == 0:\n",
    "                target_net = copy.deepcopy(policy_net)\n",
    "        #         target_net.load_state_dict(policy_net.state_dict())\n",
    "except KeyboardInterrupt:\n",
    "    iterator.close()\n",
    "    raise\n",
    "iterator.close()\n",
    "print('Pretrain Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active Learning\n",
    "pretrain_crf_list = data.sequence[:CRF_PRETRAIN_SIZE]\n",
    "pretrain_agt_list = data.sequence[:AGENT_PRETRAIN_SIZE]\n",
    "test_list = data.sequence[-TEST_SIZE:]\n",
    "validation_list = data.sequence[-TEST_SIZE - VALIDATE_SIZE : -TEST_SIZE]\n",
    "candidate_list  = data.sequence[AGENT_PRETRAIN_SIZE : AGENT_PRETRAIN_SIZE + CANDIDATE_SIZE]\n",
    "\n",
    "if INITIAL_FLAG:\n",
    "    pretrain_crf = pretrain_agt_list\n",
    "else:\n",
    "    pretrain_crf = test_list\n",
    "BUDGET = BUDGET - len(pretrain_agt_list) + len(pretrain_crf)\n",
    "\n",
    "crf.reset()\n",
    "crf.add_instances(pretrain_crf)\n",
    "crf.train()\n",
    "ground_list = pretrain_crf\n",
    "\n",
    "# count = sum([len(seq[1]) for seq in pretrain_agt_list])\n",
    "count = len(pretrain_crf)\n",
    "cost_list = [count]\n",
    "\n",
    "_, _, _, acc = crf.evaluate_acc(test_list)\n",
    "acc_list = [acc]\n",
    "_, _, _, acc_valid = crf.evaluate_acc(validation_list)\n",
    "acc_valid_list = [acc_valid]\n",
    "print (acc)\n",
    "\n",
    "qvalue_list = []\n",
    "action_mark_list = []\n",
    "prob_list = []\n",
    "seq_list = []\n",
    "seqsq_list = []\n",
    "seqsr_list = []\n",
    "steps_done = 0\n",
    "try:\n",
    "    with tqdm(range(CANDIDATE_SIZE)) as iterator:\n",
    "        for i_episode in iterator:\n",
    "            if cost_list[-1] > BUDGET:\n",
    "                break\n",
    "\n",
    "            state = crf.get_parameters()\n",
    "\n",
    "            # Select and perform an action\n",
    "            act_mrk, query_idx, qvalue = select_action(state, candidate_list, GREEDY)\n",
    "            query_instance = candidate_list.pop(query_idx)\n",
    "\n",
    "            qvalue_list.append(qvalue.item())\n",
    "            action_mark_list.append(act_mrk)\n",
    "            prob_list.append(crf.compute_entropy(query_instance)[-1]/len(query_instance[0]))\n",
    "            if act_mrk == 0:\n",
    "                seqsr_list.append(query_instance)\n",
    "            else:\n",
    "                seqsq_list.append(query_instance)\n",
    "            seq_list.append(query_instance)\n",
    "\n",
    "            # Initialize the environment and state\n",
    "            ground_list = ground_list + [query_instance]\n",
    "\n",
    "            if LOOP_CANDI == 0:\n",
    "                comb = combinations(range(len(ground_list)), 3) \n",
    "            else:\n",
    "                comb = []\n",
    "                if i_episode % 10 == 0:\n",
    "                    LOOP_SIZE += 10\n",
    "                for i in range(LOOP_SIZE):\n",
    "                    comb.append(tuple(random.sample(range(len(ground_list)), LOOP_CANDI)))\n",
    "            \n",
    "            for c_idx in comb:\n",
    "                tmp_candi_list = [ground_list[i] for i in c_idx]\n",
    "                tmp_train_list = [ground_list[i] for i in range(len(ground_list)) if i not in c_idx]\n",
    "                \n",
    "                crf.reset()\n",
    "                crf.add_instances(tmp_train_list)\n",
    "                crf.train()\n",
    "\n",
    "                old_reward, _, _ = calculate_reward(crf, validation_list, test_list, sim_weight, TRANS)\n",
    "\n",
    "                state = crf.get_parameters()\n",
    "                while len(tmp_candi_list) > 1:\n",
    "                    _, tmp_query_idx, _ = select_action(state, tmp_candi_list, GREEDY)\n",
    "                    query_instance = tmp_candi_list.pop(tmp_query_idx)\n",
    "\n",
    "                    crf.add_instances([query_instance])\n",
    "                    crf.train()\n",
    "\n",
    "                    cur_reward, _, _ = calculate_reward(crf, validation_list, test_list, sim_weight, TRANS)\n",
    "                    reward = cur_reward - old_reward\n",
    "                    old_reward = cur_reward\n",
    "\n",
    "                    # Observe new state\n",
    "                    action = data.seqs2Tensor(query_instance)\n",
    "                    reward = torch.tensor([reward], device=device)\n",
    "                    next_state = crf.get_parameters()\n",
    "\n",
    "                    # Store the transition in memory\n",
    "                    memory.push(state, action, next_state, reward, [seq for seq in tmp_candi_list])\n",
    "\n",
    "                    # Move to the next state\n",
    "                    state = next_state\n",
    "\n",
    "                    # Perform one step of the optimization (on the target network)\n",
    "                    optimize_model()\n",
    "                # Update the target network, copying all weights and biases in DQN\n",
    "            if i_episode % TARGET_UPDATE == 0:\n",
    "                target_net = copy.deepcopy(policy_net)\n",
    "            #       target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "            crf.reset()\n",
    "            crf.add_instances(ground_list)\n",
    "            crf.train()\n",
    "            \n",
    "            count += 1\n",
    "            cost_list.append(count)\n",
    "            \n",
    "            _, _, _, acc= crf.evaluate_acc(test_list)\n",
    "            acc_list.append(acc)\n",
    "            _, _, _, acc_valid= crf.evaluate_acc(validation_list)\n",
    "            acc_valid_list.append(acc_valid)\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    iterator.close()\n",
    "    raise\n",
    "iterator.close()\n",
    "print('Complete')\n",
    "print (acc_list)\n",
    "print (acc_valid_list)\n",
    "print (qvalue_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix = \"fix\" if FIX_FLAG else \"\"\n",
    "num = \"num\" if NUM_FLAG else \"\"\n",
    "ini = \"testIni\" if not INITIAL_FLAG else \"\"\n",
    "emb = \"embed\" if EMBED_FLAG else \"\"\n",
    "filename = \"./results/\" + SOURCE + str(AGENT_PRETRAIN_SIZE) + num + emb + \"_\" + str(VALIDATE_SIZE) + ini + \"_\" + str(BUDGET) + \"budget_\" + TRANS + METHOD + fix + \"_\" + STRATEGY + \"_\" + GREEDY + \"_\" + REWARD\n",
    "filename += \"_\" + str(TARGET_UPDATE) + \"step_\" + str(BATCH_SIZE) + \"batch\" + str(EPS_DECAY) + \"decay_\" + str(LOOP_SIZE) + \"loop_\"\n",
    "filename += \"_\" + str(RNN_HIDDEN) + \"rnn_\" + str(N_FILTER) + \"filter_\" + str(FILTER_SIZE) + \"size_\" + str(N_STRIDE) + \"stride\"\n",
    "\n",
    "with open(filename + \".bin\", \"wb\") as result:\n",
    "    pickle.dump((cost_list, acc_list, acc_valid_list), result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seqs in enumerate(errseq_list):\n",
    "    print ('----- step {} -----'.format(i))\n",
    "    for seq in seqs:\n",
    "        print (\"\".join(str(char) for char in seq[0]))\n",
    "        print (\", \".join(str(char) for char in seq[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(len(qvalue_list))\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, nrows=1)\n",
    "ax = axes.flatten()\n",
    "\n",
    "ax[0].plot(x, qvalue_list, color='0.5')\n",
    "x2 = []\n",
    "y2 = []\n",
    "for i in x:\n",
    "    if action_mark_list[i] == 1:\n",
    "        x2.append(i)\n",
    "        y2.append(qvalue_list[i])\n",
    "l1 = ax[0].scatter(x2, y2, color='r', marker='o')\n",
    "x2 = []\n",
    "y2 = []\n",
    "for i in x:\n",
    "    if action_mark_list[i] == 0:\n",
    "        x2.append(i)\n",
    "        y2.append(qvalue_list[i])\n",
    "l2 = ax[0].scatter(x2, y2, color='g', marker='x')\n",
    "ax[0].legend((l1,l2),\n",
    "           ('$action > \\\\epsilon$', '$action < \\\\epsilon$'))\n",
    "\n",
    "ax[0].set_title('SOD dataset with {} pretraining samples'.format(AGENT_PRETRAIN_SIZE))\n",
    "# plt.xlim(0, 20)\n",
    "ax[0].set_ylabel('Q value')\n",
    "ax[0].set_xlabel('Sequence number')\n",
    "\n",
    "# print (qvalue_list)\n",
    "ax[1].scatter(qvalue_list, prob_list)\n",
    "for i in range(len(qvalue_list)):\n",
    "    ax[1].annotate(i, (qvalue_list[i], prob_list[i]))\n",
    "ax[1].set_xlabel('Q value')\n",
    "ax[1].set_ylabel('Likelihood')\n",
    "plt.subplots_adjust(wspace=0.1)\n",
    "fig.set_size_inches(15,5)\n",
    "# plt.show()\n",
    "plt.savefig(filename + '_check.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sim beta\n",
    "with open(\"./results/conll15_200_75budget_fully_none.bin\", \"rb\") as in_file:\n",
    "    (cost_1, _, _, all_acc_1, acc_valid_1) = pickle.load(in_file)\n",
    "       \n",
    "with open(\"./results/conll15numembed_200_75budget_valid2VRL_all_te_acc_20step_5batch20decay_90loop3_64rnn_16filter_4size_2stride.bin\", \"rb\") as in_file:\n",
    "    (cost_2, all_acc_2, acc_valid_2) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/conll15numembed_200_75budget_valid2VRL_all_rand_acc_20step_5batch20decay_90loop3_64rnn_16filter_4size_2stride.bin\", \"rb\") as in_file:\n",
    "    (cost_3, all_acc_3, acc_valid_3) = pickle.load(in_file)\n",
    "\n",
    "# with open(\"./results/sod15num_200_valid2VRL_all_te_acc_20step_5batch20decay_90loop3_32rnn_16filter_4size_2stride.bin\", \"rb\") as in_file:\n",
    "#     (cost_4, all_acc_4, acc_valid_4) = pickle.load(in_file)\n",
    "    \n",
    "# with open(\"./results/sod15num_200_valid2TRL_all_te_accconf_20step_5batch20decay_150loop3_64rnn_16filter_4size_2stride.bin\", \"rb\") as in_file:\n",
    "#     (cost_5, all_acc_5, acc_valid_5) = pickle.load(in_file)\n",
    "\n",
    "# with open(\"./results/sod15num_200_testVRL_acc2_all_rand_20step_5batch20decay_90loopdecay_64rnn_16filter_4size_2stride.bin\", \"rb\") as in_file:\n",
    "#     (cost_6, in_acc_6, out_acc_6, all_acc_6, acc_valid_6) = pickle.load(in_file)\n",
    "\n",
    "# with open(\"./results/sod15num_200_testVRL_acc2_all_te_20step_5batch20decay_90loopdecay_64rnn_16filter_4size_2stride.bin\", \"rb\") as in_file:\n",
    "#     (cost_7, in_acc_7, out_acc_7, all_acc_7, acc_valid_7) = pickle.load(in_file)\n",
    "\n",
    "plt.plot(cost_1, all_acc_1,\n",
    "         cost_2, all_acc_2,\n",
    "         cost_3, all_acc_3,)\n",
    "#          cost_4, all_acc_4,)\n",
    "#          cost_5, all_acc_5,)\n",
    "#          cost_6, all_acc_6,)\n",
    "#          cost_7, acc_valid_7)\n",
    "plt.legend(['TE', 'RL: onehot', 'RL: embed', 'RL: 32', 'RL-test2V' ,'RL-test', 'RL-valid'], loc='upper left', fancybox=True, fontsize = 9)\n",
    "# plt.xlim(200, 600)\n",
    "\n",
    "plt.title('CoNLL dataset with 15 pretraining samples')\n",
    "plt.xlabel('Number of training sequences')\n",
    "plt.ylabel('Prediction accuracy')\n",
    "plt.savefig('./results/sod.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 20\n",
    "SUBSEQ_FLAG = False\n",
    "SUBSEQ_SIZE = 8\n",
    "STRATEGY = 'fully'\n",
    "BETA = 3.0\n",
    "METHOD = 'none' #selfSim, testSim\n",
    "\n",
    "pretrain_crf_list = data.sequence[:CRF_PRETRAIN_SIZE]\n",
    "pretrain_agt_list = data.sequence[:AGENT_PRETRAIN_SIZE]\n",
    "test_list = data.sequence[-TEST_SIZE:]\n",
    "validation_list = data.sequence[-TEST_SIZE - VALIDATE_SIZE : -TEST_SIZE]\n",
    "candidate_list  = data.sequence[AGENT_PRETRAIN_SIZE : AGENT_PRETRAIN_SIZE + CANDIDATE_SIZE]\n",
    "\n",
    "crf = CrfModel(data, FEAT)\n",
    "crf.add_instances(pretrain_agt_list)\n",
    "crf.train()\n",
    "\n",
    "# count = sum([len(seq[1]) for seq in pretrain_agt_list]) \n",
    "count = len(pretrain_agt_list)\n",
    "cost_list = [count]\n",
    "\n",
    "(in_acc, out_acc, all_acc, acc) = crf.evaluate_acc(test_list)\n",
    "\n",
    "in_acc_list = [in_acc]\n",
    "out_acc_list = [out_acc]\n",
    "all_acc_list = [acc]\n",
    "\n",
    "(in_acc, out_acc, all_acc, acc_valid) = crf.evaluate_acc(validation_list)\n",
    "acc_valid_list = [acc_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized and clustered test set.\n",
    "Xs = [seq[0] for seq in test_list]\n",
    "Xs.extend([seq[0] for seq in candidate_list])\n",
    "vec, _ = string_vectorize(Xs)\n",
    "validation_vec = vec[:len(test_list)].tolist()\n",
    "candidate_vec = vec[len(test_list):].tolist()\n",
    "\n",
    "print (len(validation_vec))\n",
    "print (len(candidate_vec))\n",
    "# Pre-calculate similarity: both between validation-test and validation-validate\n",
    "sim_matrix_test = np.zeros((len(candidate_vec), len(validation_vec)))\n",
    "sim_matrix_self = np.zeros((len(candidate_vec), len(candidate_vec)))\n",
    "if METHOD != 'none':\n",
    "    iterator = tqdm(range(len(candidate_vec)))\n",
    "    for i in iterator:\n",
    "        for j in range(len(validation_vec)):\n",
    "            sim_matrix_test[i, j] = 1 - scipy.spatial.distance.cosine(candidate_vec[i], validation_vec[j])\n",
    "        for j in range(len(candidate_vec)):\n",
    "            sim_matrix_self[i, j] = 1 - scipy.spatial.distance.cosine(candidate_vec[i], candidate_vec[j])\n",
    "    iterator.close()\n",
    "print ('Similarity done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visited_candidate_idx = []\n",
    "seqs_list = []\n",
    "iterator = tqdm(range(CANDIDATE_SIZE))\n",
    "for seqs_size in iterator:\n",
    "    if cost_list[-1] > BUDGET:\n",
    "        break\n",
    "    \n",
    "    # Sort the test set based on confidence.\n",
    "    prob_test_list = []\n",
    "    for i in range(len(test_list)):\n",
    "        (prob_per_token, _, prob_sum) = crf.compute_confidence(test_list[i])\n",
    "        prob_test_list.append(prob_sum)\n",
    "    rank_idx_test = np.argsort(np.array(prob_test_list), kind='mergesort').tolist()[::-1]\n",
    "\n",
    "    # Calculate the average similarity between the unlabeled samples and the selected test samples.\n",
    "    distance = []\n",
    "    if METHOD != 'none':\n",
    "        if METHOD == 'testSim':\n",
    "            distance = np.sum(sim_matrix_test[:, rank_idx_test[:M]], axis=1) / M\n",
    "        else:\n",
    "            distance = np.sum(sim_matrix_self, axis=1) / (len(candidate_vec)-1)\n",
    "        mean_dist = np.mean(distance)\n",
    "        std_dist = np.std(distance)\n",
    "#         distance = [(distance[i] - mean_dist) / std_dist for i in range(len(candidate_list))]\n",
    "\n",
    "\n",
    "    ####\n",
    "    # Compute the top-K tokens and its seq_idx: subsequence with or without SEBSEQ_FLAG\n",
    "    prob_list = []\n",
    "    subseq_idx_list = []\n",
    "    for i in range(len(candidate_list)):\n",
    "        (prob_per_token, prob_sum) = crf.compute_entropy(candidate_list[i])\n",
    "        prob_sum /= len(candidate_list[i][1])\n",
    "        if STRATEGY == 'partial':\n",
    "            subseq_idxs = []\n",
    "            subseq_prob_sum = -sys.maxsize\n",
    "            if SUBSEQ_FLAG:\n",
    "                end_p = len(prob_per_token) - SUBSEQ_SIZE + 1\n",
    "                for k in range(0, end_p): # the largest subsequence\n",
    "                    prob_tmp = sum([prob_per_token[k+j] for j in range(SUBSEQ_SIZE)]) / SUBSEQ_SIZE\n",
    "                    if prob_tmp > subseq_prob_sum:\n",
    "                        subseq_prob_sum = prob_tmp\n",
    "                        subseq_idxs = [k+j for j in range(SUBSEQ_SIZE)]\n",
    "                if end_p < 1: # if length is not longer than subseq_size\n",
    "                    subseq_prob_sum = prob_sum / len(prob_per_token)\n",
    "                    subseq_idxs = range(0, len(prob_per_token))\n",
    "            else:\n",
    "                token_sorted = np.argsort(np.array(prob_per_token), kind='mergesort').tolist()[::-1]\n",
    "                subseq_idxs = [token_sorted[k] for k in range(min(SUBSEQ_SIZE, len(prob_per_token)))]\n",
    "                subseq_prob_sum = sum([prob_per_token[k] for k in subseq_idxs]) / len(subseq_idxs)\n",
    "            prob_sum = subseq_prob_sum\n",
    "            subseq_idx_list.append(subseq_idxs)\n",
    "\n",
    "        prob_list.append(prob_sum)\n",
    "    \n",
    "    # Entropy weighted with or without similarity\n",
    "    mean_prob = np.mean(prob_list)\n",
    "    std_prob = np.std(prob_list)\n",
    "    prob_list = [(prob_list[i] - mean_prob) / std_prob for i in range(len(candidate_list))]\n",
    "\n",
    "    # norm_dist = [1/(1+math.exp(x)) for x in norm_dist]\n",
    "    score_list = []\n",
    "    for i in range(len(candidate_list)):\n",
    "        if METHOD == 'none':\n",
    "            score_list.append(prob_list[i])\n",
    "        else:\n",
    "            score_list.append(prob_list[i] * math.pow(distance[i], BETA))\n",
    "    \n",
    "    # Locate the subseq_idx with largest score\n",
    "    rank_idx = np.argsort(np.array(score_list), kind='mergesort').tolist()[::-1]\n",
    "    for i in rank_idx:\n",
    "        if i not in visited_candidate_idx:\n",
    "            seq_idx = i\n",
    "            visited_candidate_idx.append(seq_idx)\n",
    "            break\n",
    "    query_seq = candidate_list[seq_idx]\n",
    "\n",
    "    if STRATEGY == 'partial':\n",
    "        subseq_idxs = subseq_idx_list[seq_idx]\n",
    "        predict_y = crf.predict(query_seq)\n",
    "        for i in range(len(query_seq[1])):\n",
    "            if i not in subseq_idxs:\n",
    "                query_seq[1][i] = predict_y[i]\n",
    "        count += len(subseq_idxs)\n",
    "    else:\n",
    "#         count += len(query_seq[1])\n",
    "        count += 1\n",
    "    cost_list.append(count)\n",
    "    \n",
    "    crf.add_instances([query_seq])\n",
    "    seqs_list.append(query_seq)\n",
    "    crf.train()\n",
    "    (in_acc, out_acc, all_acc, acc) = crf.evaluate_acc(test_list)\n",
    "    in_acc_list.append(in_acc)\n",
    "    out_acc_list.append(out_acc)\n",
    "    all_acc_list.append(acc)\n",
    "    \n",
    "    (in_acc, out_acc, all_acc, acc_valid) = crf.evaluate_acc(validation_list)\n",
    "    acc_valid_list.append(acc_valid)\n",
    "iterator.close()\n",
    "print ('Done!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./results/\" + SOURCE + str(AGENT_PRETRAIN_SIZE) + \"_\" + str(VALIDATE_SIZE) + \"_\" + str(BUDGET) + \"budget_\" + STRATEGY + \"_\" + METHOD \n",
    "if STRATEGY == 'partial':\n",
    "    filename += \"_sub\" + str(SUBSEQ_SIZE) + str(SUBSEQ_FLAG)\n",
    "if METHOD != 'none':\n",
    "    filename += \"_beta\" + str(BETA)\n",
    "    if METHOD == 'testSim':\n",
    "        filename += \"_M\" + str(M)\n",
    "filename += \".bin\"\n",
    "\n",
    "with open(filename, \"wb\") as result:\n",
    "    pickle.dump((cost_list, in_acc_list, out_acc_list, all_acc_list, acc_valid_list), result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_q = gen_dataDistr(seqsq_list + pretrain_agt_list)\n",
    "rand_q = gen_dataDistr(seqsr_list + pretrain_agt_list)\n",
    "print (\"selected set has {} formats\".format(len(select_q)))\n",
    "print (\"rand set has {} formats\".format(len(rand_q)))\n",
    "\n",
    "# for rank, key in enumerate(sorted(uniques, key=uniques.get, reverse=True), 1):\n",
    "#     print (rank, key)\n",
    "\n",
    "data_dict = add_dataformat({}, test_list)\n",
    "data_dict = add_dataformat(data_dict, validation_list)\n",
    "data_dict = add_dataformat(data_dict, seqsq_list + seqsr_list + pretrain_agt_list)\n",
    "data_dict = add_dataformat(data_dict, candidate_list)\n",
    "print (\"{} formats overall\".format(len(data_dict)))\n",
    "\n",
    "for key, value in data_dict.items():\n",
    "    print (\"{}: {}\".format(key, str(value)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_test_ratio = len(set.intersection(set(test_q.keys()),set(select_q.keys()))) / len(test_q)\n",
    "print (\"select & test / test: {}\".format(select_test_ratio))\n",
    "\n",
    "select_valid_ratio = len(set.intersection(set(valid_q.keys()),set(select_q.keys()))) / len(valid_q)\n",
    "print (\"select & valid / valid: {}\".format(select_valid_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = []\n",
    "y1 = []\n",
    "for key, value in test_q.items():\n",
    "    x1.append(data_dict[key])\n",
    "    y1.append(value)\n",
    "l1 = plt.bar(x1, y1)\n",
    "\n",
    "x2 = []\n",
    "y2 = []\n",
    "for key, value in valid_q.items():\n",
    "    x2.append(data_dict[key])\n",
    "    y2.append(value)\n",
    "l2 = plt.bar(x2, y2)\n",
    "\n",
    "x3 = []\n",
    "y3 = []\n",
    "for key, value in select_q.items():\n",
    "    x3.append(data_dict[key])\n",
    "    y3.append(value)\n",
    "l3 = plt.bar(x3, y3)\n",
    "\n",
    "x4 = []\n",
    "y4 = []\n",
    "for key, value in rand_q.items():\n",
    "    x4.append(data_dict[key])\n",
    "    y4.append(value)\n",
    "l4 = plt.bar(x4, y4)\n",
    "\n",
    "plt.title('data distribution')\n",
    "# plt.xlim(-5, 155)\n",
    "plt.legend((l1, l2, l3, l4), ('test', 'validation', 'select', 'rand'))\n",
    "# plt.show()\n",
    "\n",
    "# x4 = []\n",
    "# y4 = []\n",
    "# for key, value in candidate_q.items():\n",
    "#     x4.append(data_dict[key])\n",
    "#     y4.append(value)\n",
    "# plt.bar(x4, y4)\n",
    "# plt.title('candidate distribution')\n",
    "# plt.xlim(-5, 155)\n",
    "plt.savefig(filename + '_distr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial window size w\n",
    "# sod: w=9\n",
    "# sdh: w=8\n",
    "# ibm: w=17\n",
    "\n",
    "# SOD\n",
    "with open(\"./results/sod_fully_none_Truenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_f, in_acc_f, out_acc_f, all_acc_f) = pickle.load(in_file)\n",
    "       \n",
    "with open(\"./results/sod1000_fully_selfSim_beta3.0_Truenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_8, in_acc_8, out_acc_8, all_acc_8) = pickle.load(in_file)\n",
    "    \n",
    "with open(\"./results/sod_partial_none_sub9False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_9, in_acc_9, out_acc_9, all_acc_9) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/sod_partial_selfSim_sub8False_beta1.0_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_11, in_acc_11, out_acc_11, all_acc_11) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/sod1000_partial_selfSim_sub8False_beta3.0_Truenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_self_part, in_acc_self_part, out_acc_self_part, all_acc_self_part) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/sod_fully_testSim_beta1.0_M100_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_test_part, in_acc_test_part, out_acc_test_part, all_acc_test_part) = pickle.load(in_file)\n",
    "\n",
    "# plt.rc('text', usetex=True)\n",
    "# plt.rc('font', family='serif')\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1)\n",
    "ax = axes.flatten()\n",
    "\n",
    "ax[0].set_xlabel(\"Number of training labels\", fontsize=21)\n",
    "ax[0].set_ylabel(\"Predictive accuracy\", fontsize=21)\n",
    "ax[0].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[1].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[2].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[0].grid()\n",
    "ax[0].plot(cost_f, all_acc_f, linestyle=':')\n",
    "ax[0].plot(cost_8, all_acc_8, linestyle='--')\n",
    "ax[0].plot(cost_9, all_acc_9)\n",
    "ax[0].plot(cost_11, all_acc_11)\n",
    "ax[0].plot(cost_self_part, all_acc_self_part)\n",
    "ax[0].plot(cost_test_part, all_acc_test_part, c='black')\n",
    "ax[0].set_xlim([200,600])\n",
    "ax[0].set_title('Building A', fontsize=22)\n",
    "leg = ax[0].legend(['TE', 'denTE', 'TE-part', 'transTE', 'denTE-part', 'transTE-part'], \n",
    "                   loc='lower right', fancybox=True, fontsize = 16)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "# plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "\n",
    "# SDH\n",
    "with open(\"./results/sdh_fully_none_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_f, in2_acc_f, out_acc_f, all2_acc_f) = pickle.load(in_file)\n",
    "       \n",
    "with open(\"./results/sdh_fully_selfSim_beta1.0_Truenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_8, in2_acc_8, out_acc_8, all2_acc_8) = pickle.load(in_file)\n",
    "    \n",
    "with open(\"./results/sdh_partial_none_sub8False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_9, in2_acc_9, out_acc_9, all2_acc_9) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/sdh_fully_testSim_beta1.0_M100_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_11, in2_acc_11, out_acc_11, all2_acc_11) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/sdh_partial_selfSim_sub8False_beta0.5_Truenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_self_part, in2_acc_self_part, out_acc_self_part, all2_acc_self_part) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/sdh1000_partial_testSim_sub8False_beta1.0_M100_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_test_part, in2_acc_test_part, out_acc_test_part, all2_acc_test_part) = pickle.load(in_file)\n",
    "\n",
    "\n",
    "ax[1].set_xlabel(\"Number of training labels\", fontsize=21)\n",
    "ax[1].set_ylabel(\"Predictive accuracy\", fontsize=21)\n",
    "ax[1].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[1].grid()\n",
    "ax[1].plot(cost2_f, all2_acc_f, linestyle=\":\")\n",
    "ax[1].plot(cost2_8, all2_acc_8, linestyle='--')\n",
    "ax[1].plot(cost2_9, all2_acc_9)\n",
    "ax[1].plot(cost2_11, all2_acc_11)\n",
    "ax[1].plot(cost2_self_part, all2_acc_self_part)\n",
    "ax[1].plot(cost2_test_part, all2_acc_test_part, c='black')\n",
    "ax[1].set_ylim([0.85, 0.978])\n",
    "ax[1].set_xlim([300,1000])\n",
    "ax[1].set_title('Building B', fontsize=22)\n",
    "leg = ax[1].legend(['TE', 'denTE', 'TE-part', 'transTE', 'denTE-part', 'transTE-part'], \n",
    "                   loc='lower right', fancybox=True, fontsize = 16)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "\n",
    "# IBM\n",
    "with open(\"./results/ibm_partial_none_sub15False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_f, in3_acc_f, out_acc_f, all3_acc_f) = pickle.load(in_file)\n",
    "       \n",
    "with open(\"./results/ibm1000_partial_testSim_sub13False_beta1.0_M10_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_8, in3_acc_8, out_acc_8, all3_acc_8) = pickle.load(in_file)\n",
    "    \n",
    "with open(\"./results/ibm_partial_none_sub19False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_9, in3_acc_9, out_acc_9, all3_acc_9) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/ibm_fully_testSim_beta1.0_M100_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_11, in3_acc_11, out_acc_11, all3_acc_11) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/ibm_partial_selfSim_sub17False_beta1.0_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_self_part, in3_acc_self_part, out_acc_self_part, all3_acc_self_part) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/ibm_fully_none_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_test_part, in3_acc_test_part, out_acc_test_part, all3_acc_test_part) = pickle.load(in_file)\n",
    "\n",
    "\n",
    "ax[2].set_xlabel(\"Number of training labels\", fontsize=21)\n",
    "ax[2].set_ylabel(\"Predictive accuracy\", fontsize=21)\n",
    "ax[2].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[2].grid()\n",
    "ax[2].plot(cost3_f, all3_acc_f, linestyle=\":\")\n",
    "ax[2].plot(cost3_8, all3_acc_8, linestyle='--')\n",
    "ax[2].plot(cost3_9, all3_acc_9)\n",
    "ax[2].plot(cost3_11, all3_acc_11)\n",
    "ax[2].plot(cost3_self_part, all3_acc_self_part)\n",
    "ax[2].plot(cost3_test_part, all3_acc_test_part, c='black')\n",
    "ax[2].set_ylim([0.745, 0.924])\n",
    "ax[2].set_xlim([200,1000])\n",
    "ax[2].set_title('Building C', fontsize=22)\n",
    "leg = ax[2].legend(['TE', 'denTE', 'TE-part', 'transTE', 'denTE-part', 'transTE-part'], \n",
    "                   loc='lower right', fancybox=True, fontsize = 16)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "fig.set_size_inches(28,4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial window size w\n",
    "# sod: w=9\n",
    "# sdh: w=8\n",
    "# ibm: w=17\n",
    "\n",
    "# SOD\n",
    "with open(\"./results/sod_fully_none_Truenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_f, in_acc_f, out_acc_f, all_acc_f) = pickle.load(in_file)\n",
    "       \n",
    "with open(\"./results/sod1000_partial_none_sub5False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_8, in_acc_8, out_acc_8, all_acc_8) = pickle.load(in_file)\n",
    "    \n",
    "with open(\"./results/sod_partial_none_sub9False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_9, in_acc_9, out_acc_9, all_acc_9) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/sod_partial_none_sub12False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost_11, in_acc_11, out_acc_11, all_acc_11) = pickle.load(in_file)\n",
    "\n",
    "# plt.rc('text', usetex=True)\n",
    "# plt.rc('font', family='arial')\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1)\n",
    "ax = axes.flatten()\n",
    "\n",
    "ax[0].set_xlabel(\"Number of training labels\", fontsize=21)\n",
    "ax[0].set_ylabel(\"Predictive accuracy\", fontsize=21)\n",
    "ax[0].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[1].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[2].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[0].grid()\n",
    "ax[0].plot(cost_f, all_acc_f, linestyle=':')\n",
    "ax[0].plot(cost_8, all_acc_8, c='orange')\n",
    "ax[0].plot(cost_9, all_acc_9, c='green')\n",
    "ax[0].plot(cost_11, all_acc_11, c='red')\n",
    "ax[0].set_xlim([200,600])\n",
    "ax[0].set_title('Building A', fontsize=22)\n",
    "leg = ax[0].legend(['Full', r'w=5', r'w=9', r'w=12'], loc='lower right', fancybox=True, fontsize = 16)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "# plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "\n",
    "# SDH\n",
    "with open(\"./results/sdh_fully_none_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_f, in2_acc_f, out_acc_f, all2_acc_f) = pickle.load(in_file)\n",
    "       \n",
    "with open(\"./results/sdh_partial_none_sub5False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_8, in2_acc_8, out_acc_8, all2_acc_8) = pickle.load(in_file)\n",
    "    \n",
    "with open(\"./results/sdh_partial_none_sub8False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_9, in2_acc_9, out_acc_9, all2_acc_9) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/sdh_partial_none_sub14False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost2_11, in2_acc_11, out_acc_11, all2_acc_11) = pickle.load(in_file)\n",
    "\n",
    "ax[1].set_xlabel(\"Number of training labels\", fontsize=21)\n",
    "ax[1].set_ylabel(\"Predictive accuracy\", fontsize=21)\n",
    "ax[1].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[1].grid()\n",
    "ax[1].plot(cost2_f, all2_acc_f, linestyle=\":\")\n",
    "ax[1].plot(cost2_8, all2_acc_8, c='orange')\n",
    "ax[1].plot(cost2_9, all2_acc_9, c='green')\n",
    "ax[1].plot(cost2_11, all2_acc_11, c='red')\n",
    "ax[1].set_ylim([0.83, 0.978])\n",
    "ax[1].set_xlim([300,1000])\n",
    "ax[1].set_title('Building B', fontsize=22)\n",
    "leg = ax[1].legend(['Full', 'w=5', 'w=8', 'w=14'],\n",
    "                   loc='lower right', fancybox=True, fontsize = 16)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "\n",
    "# IBM\n",
    "with open(\"./results/ibm_partial_none_sub15False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_f, in3_acc_f, out_acc_f, all3_acc_f) = pickle.load(in_file)\n",
    "       \n",
    "with open(\"./results/ibm_partial_none_sub11False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_8, in3_acc_8, out_acc_8, all3_acc_8) = pickle.load(in_file)\n",
    "    \n",
    "with open(\"./results/ibm_partial_none_sub19False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_9, in3_acc_9, out_acc_9, all3_acc_9) = pickle.load(in_file)\n",
    "\n",
    "with open(\"./results/ibm_partial_none_sub7False_Falsenorm.bin\", \"rb\") as in_file:\n",
    "    (cost3_11, in3_acc_11, out_acc_11, all3_acc_11) = pickle.load(in_file)\n",
    "\n",
    "ax[2].set_xlabel(\"Number of training labels\", fontsize=21)\n",
    "ax[2].set_ylabel(\"Predictive accuracy\", fontsize=21)\n",
    "ax[2].tick_params(axis = 'both', which = 'major', labelsize = 17)\n",
    "ax[2].grid()\n",
    "ax[2].plot(cost3_f, all3_acc_f, linestyle=':')\n",
    "ax[2].plot(cost3_8, all3_acc_8, c='orange')\n",
    "ax[2].plot(cost3_9, all3_acc_9, c='green')\n",
    "ax[2].plot(cost3_11, all3_acc_11, c='red')\n",
    "ax[2].set_xlim([200,1000])\n",
    "# ax[2].set_ylim([0.83, 0.978])\n",
    "ax[2].set_title('Building C', fontsize=22)\n",
    "leg = ax[2].legend(['Full', 'w=15', 'w=19', 'w=23'], \n",
    "                   loc='lower right', fancybox=True, fontsize = 16)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "fig.set_size_inches(28,4)\n",
    "plt.show()\n",
    "# plt.tick_params(labelsize=20)\n",
    "# plt.savefig('perp1.png', bbox_inches='tight')\n",
    "    \n",
    "# plt.plot(cost_f, all_acc_f,\n",
    "#          cost_8, all_acc_8,\n",
    "#          cost_9, all_acc_9,\n",
    "#          cost_11, all_acc_11,\n",
    "#          cost_self_part, all_acc_self_part,\n",
    "#          cost_test_part, all_acc_test_part)\n",
    "# plt.legend(['TE', 'denTE', 'TE-part', 'transTE', 'denTE-part', 'transTE-part'], loc='lower right', fancybox=True, fontsize = 12)\n",
    "# # plt.ylim(0.86, 0.97)\n",
    "\n",
    "# plt.title('SOD dataset with 5 pretraining samples')\n",
    "# plt.xlabel('Number of training labels')\n",
    "# plt.ylabel('Prediction accuracy')\n",
    "# plt.savefig('./results/sod.png', bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6",
   "language": "python",
   "name": "ll5fy36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
